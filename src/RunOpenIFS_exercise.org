#+OPTIONS: toc:nil
#+LATEX_CLASS_OPTIONS: [12pt, a4paper]
#+LATEX_HEADER: \input{exercise_header.tex}
#+BIND: org-export-publishing-directory "../doc"

*LABORATORY COURSE IN NUMERICAL METEOROLOGY*\\
*Exercise 3, Fri Feb 5 14:15-16:00 2016, E206*

* Running OpenIFS

** Running batch jobs

Large computing servers use batch queue systems to schedule and run
computing jobs (batch jobs) from multiple users. Taito uses [[https://computing.llnl.gov/linux/slurm/][SLURM]]
batch queue system.

User writes a batch job as a shell script, and then submits the script
to the batch system. Batch system then schedules and runs the job
according to the user's resource requests and the queue policies.

When the batch system finds a suitable slot for the user's job, it
first reserves the resources to the user according to the user's
request. Then, it executes one copy of the job script until the script
finishes or it runs out of the reserved time. The batch system charges
user's account (project) for the reserved resources, whether the
job actually uses them or not, for the time that the script is
running.

Following the theme of the previous exercises, we will write a script
that writes the batch job script. This is slightly more flexible and
gives at least two advantages compared to just writing a batch job
script directly, which is somewhat more common (you can find examples
in Taito user guide).

The first advantage is that we notice trivial mistakes in our script,
such as incorrect path names, immediately. This is because the regular
part of the script executes immediately, whereas the commands within the
batch job scripts are executed only after a possibly long queuing time.

The second advantage is that we separate the sequential, and possible
I/O heavy, pre-processing steps from the parallel stage of the
job. We can avoid reserving (and getting billed for) the parallel
computing resources during simple pre-preprocessing.

** Acceptance test

After building an application, we usually first check that the built
binary gives correct results. Let's write a script that runs [[https://software.ecmwf.int/wiki/display/OIFS/Testing+the+installation][OpenIFS
Acceptance test]].

As usual, you can download the script from
[[https://raw.githubusercontent.com/jlento/NumLab2016/master/scripts/oifs_run_acceptance_taito.bash]]
for easier viewing and editing.

*** Environment setup

We will use the same environment setup script
~oifs_env_gnu_taito.bash~ as we used when we built OpenIFS. This way
the environment is consistently defined and all the variables that
were defined at build time in the environment setup script are
available at runtime, too. In a way, you can view the environment
setup script as a "module" for OpenIFS. (Note: It is possible to
define own modules, which work exactly like the system enviroment
modules, too!)

*** Runtime parameters

It is usually a good practice to put the parameters that most likely
need attention by the user at the top of the script.

I plan to run OpenIFS with 2 MPI tasks and 2 CPU cores for each task,
i.e. a total of 4 CPU cores. I plan to reserve the resources for 10
minutes, and submit the job to test partition (queue).

#+BEGIN_SRC bash -n :tangle ../scripts/oifs_run_acceptance_taito.bash

# Batch job resource request specifications

ntasks=2
nthreads=2
rtime=10
partition=test
#+END_SRC

*** Input files

Let us next prepare the directory in which the experiment is run. First, we
unpack the ~t21test~ case from the OpenIFS source package into the work
directory, and enter the directory containing the input files.

#+BEGIN_SRC bash +n :tangle ../scripts/oifs_run_acceptance_taito.bash
# Set up input files

sdir=${USERAPPL}/oifs/src
ver=oifs38r1
cd ${WRKDIR}
tar --strip-components=1 -x -f ${sdir}/${ver}.t*gz ${ver}/t21test
cd t21test
#+END_SRC

Note, you will likely need to edit ~sdir~ variable, or make a softlink
with ~ln -s ...~ from the actual source tar ball to ~sdir~.

*** Modifying OpenIFS namelist runtime parameters

We need to modify some Fortran 90 namelist parameters in the ~fort.4~
file for the acceptance test. Now, this task of modifying a template
file is something we need to repeat often, and thus should try to
automate. Of course we could just open the file in an editor before
submitting the job, search for the parameters from the file, change
their values, save the modified file, and close the editor. After a
while that becomes tedious, and is error prone as we need to be extra
careful to set the parameters both in the job file and the input file
so that they match.

Here I define a function that takes the list of parameters to modify
and their values as arguments, and modifies the ~fort.4~ file. The
actual function call is below the definition.

#+BEGIN_SRC bash +n :tangle ../scripts/oifs_run_acceptance_taito.bash
# Modify fort.4 namelist

fixfort4() {
    local name value prog=""
    for arg in "$@"; do
        name="${arg%%=*}"
	value=$(printf %q "${arg#*=}")
	value="${value//\//\/}"
        prog="s/(^|[ ,])(${name} *=)[^,]*/\\1\\2 ${value}/"$'\n'"$prog"
    done
    sed -i -r -e "$prog" fort.4
}
export -f fixfort4
fixfort4 NPROC=${ntasks} LREFOUT=true NSTOP=144
#+END_SRC

Congratulations, if you can figure out how this function exactly
works!  Note, although I'm trying to avoid some of the most trivial
quotation issues, this is not a real parser for generic Fortran
namelists.

*Q:* Find examples of valid Fortran namelists and variables/values
     that ~fixfort4~ fails with.

*** OpenMP threads

Environment variable ~OMP_NUM_THREADS~ tells the program how many
OpenMP threads each process (MPI task) can run. The threads run most
efficiently if each thread gets a core, usually.

#+BEGIN_SRC bash +n :tangle ../scripts/oifs_run_acceptance_taito.bash
# Se the number OpenMP threads

export OMP_NUM_THREADS=${nthreads}
#+END_SRC

*** Batch job script

In taito, SLURM copies the environment variables from the shell, and
runs the batch job script in the same directory, in which the
sbatch command was given. This allows us to keep the job script
minimal. Here I use sbatch command line options to specify the job
resource request.

#+BEGIN_SRC bash -n :tangle ../scripts/oifs_run_acceptance_taito.bash
# Create a batch job script and submit it

sbatch -n ${ntasks} -c ${nthreads} -t ${rtime} -p ${partition} <<EOF
#!/bin/bash
srun ${OIFS_DEST_DIR}/oifs/bin/master.exe -e epc8
EOF
#+END_SRC

The script generates the batch job script on the fly using bash's here
document. The batch job script itself contains only the shebang that
SLURM requires, and the ~srun~ command that launches the parallel MPI
job on the compute nodes.

SLURM's integrated MPI program launcher ~srun~ knows
about the job's allocation details that we specified with ~sbatch~
command, and usually places the MPI tasks on different cores,
reasonably well, etc.

Note, I specify the executable name using the variable defined in the
environment setup file, so it is consistent with the environment.

*Q:* I could have placed the sbatch-command options, i.e. the resource
     request specification, inside the job script, equally well. What
     would that look like?

** Scalability test

As we increase the number of MPI processes and threads, the parallel
overhead from inter-process communication, sequential parts of the
code and what not, is increasing, and finally eats away all extra
performance gained by increasing resources. In general, the limit
where using more resources is still efficient depends on the balance
between computation and communication. Basically, you can use more
tasks for the larger jobs than the small ones. In practice testing is the
simplest way to know how well an application scales with a given
system. For further details, see [[https://en.wikipedia.org/wiki/Amdahl%27s_law][Amdahl's law]] and [[https://en.wikipedia.org/wiki/Parallel_computing][Parallel computing]]
in Wikipedia.

When writing scalability or other benchmarks, there are couple of
details that we need to pay attention to. First, we need a good
measurement. OpenIFS outputs timing information from each
iteration. We may need to exclude the first or the last ones, but
otherwise the average of these would suite well. The second detail to
watch is that all benchmark jobs run on equivalent resources. The
results for some jobs could be biased if there is an another job on
the same computing node which is blocking some shared resource, for
example. Also, in taito, there are nodes with Sandy Bridge CPUs and
nodes with Haswell CPUs. Haswell nodes have 24 cores, whereas Sandy
Bridge nodes have 16 cores, and there are some other minor differences
in the different CPU types, too.

** Exercises

*** Acceptance test

Run the acceptance test with both the OpenIFS binary which you
compiled with GNU compiler and with the OpenIFS binary which you
compiled with Intel compiler. The result file ~res_*~ should actually
report that the maximum error is over 1% and the calculations are NOT
correct, but that is fine. The t21test reference was generated with an
OpenIFS version that has a different convection scheme, and the
results should differ. (Would be nice to have a test for the current
convection scheme, too.)

You can run the run script directly from GitHub similarly to the build
script earlier:

#+BEGIN_SRC bash :results silent
url=https://raw.githubusercontent.com/jlento/NumLab2016/master/scripts
bash <(curl -s ${url}/oifs_{env_gnu,run_acceptance}_taito.bash)
#+END_SRC

*** Scaling test

Run the scaling test with both GNU and Intel versions of the
executable. You will need to modify the sbatch command and the job
script in the ~oifs_run_acceptance_taito.bash~ file to something like

#+BEGIN_SRC bash :tangle ../scripts/oifs_run_scalability_taito.bash
export OMP_NUM_THREADS=1
sbatch -N 1 --exclusive  -t ${rtime} -p ${partition} <<EOF
#!/bin/bash
for ntasks in 1 2 4 8 16; do
    fixfort4 NPROC=\${ntasks} LREFOUT=false NSTOP=6
    srun -n \${ntasks} -o out.\${ntasks} \
        ${OIFS_DEST_DIR}/oifs/bin/master.exe -e epc8
done
EOF
#+END_SRC

*Q:* Why there is backslash ~\~ before the variable ~${ntasks}~ in the
     script?

:scalability:
#+BEGIN_SRC bash :exports none
bash <(cat scripts/oifs_{env_gnu,run_acceptance}_taito.bash \
       <(echo "scancel -u $USER") scripts/oifs_run_scalability_taito.bash)
#+END_SRC
:END:

Write a script (I'd use bash + awk) that calculates the average timing
of the last 6 iterations from all ~out.*~ files (for each compiler
separately), and outputs the results to tables which are easy to plot
with gnuplot, for example. Plot the data and analyze the results.
